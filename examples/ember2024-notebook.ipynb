{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320d6c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zheng/VisualStudioCodeProjects/EMBER2024/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('default')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import thrember\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import altair as alt\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "alt.renderers.enable('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af906f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/zheng/VisualStudioCodeProjects/EMBER2024/database/\" # change this to where you unzipped the download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66713c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, challenge_df = thrember.read_metadata(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b72ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672000, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-45f6cd8c480549199124977d37ebfbc3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-45f6cd8c480549199124977d37ebfbc3.vega-embed details,\n",
       "  #altair-viz-45f6cd8c480549199124977d37ebfbc3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-45f6cd8c480549199124977d37ebfbc3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-45f6cd8c480549199124977d37ebfbc3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-45f6cd8c480549199124977d37ebfbc3\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-46b542847a460c34ee35d150124a0efa\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"file_type\", \"legend\": {\"values\": [\"Win32\", \"Win64\", \"Dot_Net\", \"APK\", \"ELF\", \"PDF\"]}, \"scale\": {\"range\": [\"#4c78a8\", \"#54a24b\", \"#f58518\", \"#88d27a\", \"#9ecae9\", \"#ffbf79\"]}, \"type\": \"nominal\"}, \"x\": {\"axis\": {\"title\": \"Week First Seen\"}, \"field\": \"week\", \"type\": \"ordinal\"}, \"y\": {\"axis\": {\"title\": \"File Type\"}, \"field\": \"count\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-46b542847a460c34ee35d150124a0efa\": [{\"file_type\": \"PDF\", \"week\": 57, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 57, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 51, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 60, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 41, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 15, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 16, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 10, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 41, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 14, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 28, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 35, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 33, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 21, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 40, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 21, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 62, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 4, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 59, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 7, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 45, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 63, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 53, \"count\": 5045}, {\"file_type\": \"PDF\", \"week\": 5, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 37, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 9, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 38, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 16, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 16, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 35, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 28, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 11, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 51, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 42, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 52, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 60, \"count\": 481}, {\"file_type\": \"ELF\", \"week\": 53, \"count\": 511}, {\"file_type\": \"APK\", \"week\": 1, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 59, \"count\": 499}, {\"file_type\": \"ELF\", \"week\": 7, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 23, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 50, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 58, \"count\": 4922}, {\"file_type\": \"ELF\", \"week\": 4, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 59, \"count\": 5068}, {\"file_type\": \"ELF\", \"week\": 43, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 24, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 47, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 24, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 2, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 18, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 41, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 29, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 9, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 62, \"count\": 400}, {\"file_type\": \"PDF\", \"week\": 56, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 39, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 50, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 14, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 39, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 50, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 18, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 3, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 3, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 51, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 13, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 19, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 32, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 62, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 37, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 34, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 4, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 58, \"count\": 511}, {\"file_type\": \"PDF\", \"week\": 25, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 17, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 45, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 19, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 31, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 14, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 20, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 30, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 34, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 13, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 57, \"count\": 5031}, {\"file_type\": \"PDF\", \"week\": 61, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 37, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 11, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 38, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 6, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 34, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 8, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 10, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 27, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 20, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 21, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 15, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 3, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 50, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 43, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 20, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 28, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 28, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 41, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 55, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 30, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 48, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 17, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 46, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 44, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 54, \"count\": 533}, {\"file_type\": \"ELF\", \"week\": 5, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 6, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 38, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 7, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 49, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 33, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 24, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 19, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 25, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 30, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 44, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 16, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 11, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 31, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 46, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 52, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 12, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 31, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 29, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 1, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 29, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 48, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 13, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 56, \"count\": 485}, {\"file_type\": \"Dot_Net\", \"week\": 42, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 26, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 27, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 8, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 44, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 0, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 52, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 38, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 0, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 59, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 40, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 29, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 61, \"count\": 5016}, {\"file_type\": \"ELF\", \"week\": 37, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 35, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 58, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 36, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 53, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 26, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 42, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 30, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 48, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 5, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 4, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 12, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 43, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 10, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 22, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 18, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 0, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 54, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 26, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 47, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 39, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 1, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 7, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 24, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 52, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 56, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 27, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 19, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 46, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 61, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 15, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 44, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 57, \"count\": 487}, {\"file_type\": \"APK\", \"week\": 49, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 55, \"count\": 4961}, {\"file_type\": \"APK\", \"week\": 3, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 13, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 62, \"count\": 4938}, {\"file_type\": \"APK\", \"week\": 51, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 61, \"count\": 602}, {\"file_type\": \"APK\", \"week\": 2, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 22, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 53, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 36, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 63, \"count\": 4956}, {\"file_type\": \"Dot_Net\", \"week\": 33, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 36, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 5, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 40, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 55, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 8, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 49, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 32, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 9, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 23, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 10, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 6, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 20, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 18, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 43, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 12, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 35, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 17, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 46, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 42, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 22, \"count\": 5000}, {\"file_type\": \"Dot_Net\", \"week\": 1, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 49, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 55, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 11, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 54, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 27, \"count\": 500}, {\"file_type\": \"PDF\", \"week\": 58, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 0, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 60, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 26, \"count\": 5000}, {\"file_type\": \"ELF\", \"week\": 22, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 39, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 40, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 25, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 9, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 21, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 25, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 14, \"count\": 1000}, {\"file_type\": \"APK\", \"week\": 45, \"count\": 4000}, {\"file_type\": \"Dot_Net\", \"week\": 60, \"count\": 4979}, {\"file_type\": \"Dot_Net\", \"week\": 47, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 23, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 8, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 32, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 36, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 12, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 34, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 47, \"count\": 4000}, {\"file_type\": \"APK\", \"week\": 23, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 33, \"count\": 1000}, {\"file_type\": \"Dot_Net\", \"week\": 2, \"count\": 5000}, {\"file_type\": \"APK\", \"week\": 32, \"count\": 4000}, {\"file_type\": \"PDF\", \"week\": 2, \"count\": 1000}, {\"file_type\": \"ELF\", \"week\": 45, \"count\": 500}, {\"file_type\": \"APK\", \"week\": 15, \"count\": 4000}, {\"file_type\": \"ELF\", \"week\": 48, \"count\": 500}, {\"file_type\": \"ELF\", \"week\": 17, \"count\": 500}, {\"file_type\": \"Dot_Net\", \"week\": 56, \"count\": 4994}, {\"file_type\": \"ELF\", \"week\": 63, \"count\": 491}, {\"file_type\": \"Dot_Net\", \"week\": 54, \"count\": 5090}, {\"file_type\": \"Dot_Net\", \"week\": 6, \"count\": 5000}, {\"file_type\": \"PDF\", \"week\": 63, \"count\": 1000}, {\"file_type\": \"PDF\", \"week\": 31, \"count\": 1000}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a 'week' column to the dataframe\n",
    "plotdf = pl.concat([train_df, test_df])\n",
    "start_date = pd.Timestamp(\"2023-09-24\")\n",
    "plotdf = plotdf.with_columns(\n",
    "    pl.from_epoch(\"first_submission_date\", time_unit=\"s\").alias(\"first_submission_dt\")\n",
    ")\n",
    "plotdf = plotdf.with_columns(\n",
    "    (\n",
    "        (pl.col(\"first_submission_dt\") - pl.lit(start_date)).dt.total_days() // 7\n",
    "    ).cast(pl.Int64).alias(\"week\")\n",
    ")\n",
    "\n",
    "print(plotdf.shape)\n",
    "\n",
    "# Plot file types across weeks\n",
    "gbdf = plotdf.group_by([\"file_type\", \"week\"]).agg(pl.len().alias(\"count\"))\n",
    "alt.Chart(gbdf).mark_bar().encode(\n",
    "    alt.X('week:O', axis=alt.Axis(title='Week First Seen')),\n",
    "    alt.Y('count:Q', axis=alt.Axis(title='File Type')),\n",
    "        alt.Color('file_type:N', scale=alt.Scale(range=[\"#4c78a8\", \"#54a24b\", \"#f58518\",  \"#88d27a\",  \"#9ecae9\", \"#ffbf79\"]),\n",
    "              legend=alt.Legend(values=[\"Win32\", \"Win64\", \"Dot_Net\", \"APK\", \"ELF\", \"PDF\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501106eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>family</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;wacatac&quot;</td><td>20603</td></tr><tr><td>&quot;jiagu&quot;</td><td>9515</td></tr><tr><td>&quot;mirai&quot;</td><td>9246</td></tr><tr><td>&quot;agenttesla&quot;</td><td>9075</td></tr><tr><td>&quot;xworm&quot;</td><td>8114</td></tr><tr><td>&quot;spymax&quot;</td><td>7181</td></tr><tr><td>&quot;wapron&quot;</td><td>6963</td></tr><tr><td>&quot;heracles&quot;</td><td>6274</td></tr><tr><td>&quot;njrat&quot;</td><td>5622</td></tr><tr><td>&quot;mobidash&quot;</td><td>4038</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌────────────┬───────┐\n",
       "│ family     ┆ count │\n",
       "│ ---        ┆ ---   │\n",
       "│ str        ┆ u32   │\n",
       "╞════════════╪═══════╡\n",
       "│ wacatac    ┆ 20603 │\n",
       "│ jiagu      ┆ 9515  │\n",
       "│ mirai      ┆ 9246  │\n",
       "│ agenttesla ┆ 9075  │\n",
       "│ xworm      ┆ 8114  │\n",
       "│ spymax     ┆ 7181  │\n",
       "│ wapron     ┆ 6963  │\n",
       "│ heracles   ┆ 6274  │\n",
       "│ njrat      ┆ 5622  │\n",
       "│ mobidash   ┆ 4038  │\n",
       "└────────────┴───────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of occurrences of each family\n",
    "family_counts = plotdf.select(\n",
    "    pl.col(\"family\").value_counts().alias(\"family_counts\")\n",
    ").unnest(\"family_counts\")\n",
    "family_counts = (\n",
    "    plotdf.filter(pl.col(\"family\").is_not_null())\n",
    "          .select(pl.col(\"family\").value_counts())\n",
    "          .unnest(\"family\")\n",
    "          .sort(\"count\", descending=True)\n",
    ")\n",
    "family_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ab49b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>behavior</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;backdoor&quot;</td><td>30317</td></tr><tr><td>&quot;phishing&quot;</td><td>21778</td></tr><tr><td>&quot;spyware&quot;</td><td>18817</td></tr><tr><td>&quot;dropper&quot;</td><td>10230</td></tr><tr><td>&quot;adware&quot;</td><td>9798</td></tr><tr><td>&quot;downloader&quot;</td><td>7560</td></tr><tr><td>&quot;banker&quot;</td><td>6155</td></tr><tr><td>&quot;pua&quot;</td><td>4905</td></tr><tr><td>&quot;riskware&quot;</td><td>4266</td></tr><tr><td>&quot;webshell&quot;</td><td>3866</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌────────────┬───────┐\n",
       "│ behavior   ┆ count │\n",
       "│ ---        ┆ ---   │\n",
       "│ str        ┆ u32   │\n",
       "╞════════════╪═══════╡\n",
       "│ backdoor   ┆ 30317 │\n",
       "│ phishing   ┆ 21778 │\n",
       "│ spyware    ┆ 18817 │\n",
       "│ dropper    ┆ 10230 │\n",
       "│ adware     ┆ 9798  │\n",
       "│ downloader ┆ 7560  │\n",
       "│ banker     ┆ 6155  │\n",
       "│ pua        ┆ 4905  │\n",
       "│ riskware   ┆ 4266  │\n",
       "│ webshell   ┆ 3866  │\n",
       "└────────────┴───────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of occurrences of each behavior tag\n",
    "plotdf_explode = plotdf.filter(pl.col(\"behavior\").list.len() > 0).explode(\"behavior\")\n",
    "behavior_counts = (plotdf_explode.group_by(\"behavior\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True))\n",
    "behavior_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "935c3c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Processing Multi-File-Type Dataset ===\n",
      "Dataset contains: APK, .NET, PDF, ELF files\n",
      "Creating vectorized features for all file types...\n",
      "Preparing to vectorize raw features\n",
      "Vectorizing training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 546000/546000 [22:56<00:00, 396.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126000/126000 [05:07<00:00, 409.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing challenge set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6315/6315 [00:15<00:00, 396.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading vectorized data...\n",
      "Training set shape: (546000, 2568)\n",
      "Test set shape: (126000, 2568)\n",
      "Challenge set shape: (6315, 2568)\n",
      "Multi-file-type dataset ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Define database path for all file types (APK + .NET + PDF + ELF)\n",
    "data_path = '/Users/zheng/VisualStudioCodeProjects/EMBER2024/database/'\n",
    "\n",
    "print(\"=== Processing Multi-File-Type Dataset ===\")\n",
    "print(\"Dataset contains: APK, .NET, PDF, ELF files\")\n",
    "\n",
    "# 1. Vectorise features for all file types\n",
    "print(\"Creating vectorized features for all file types...\")\n",
    "thrember.create_vectorized_features(data_path)\n",
    "\n",
    "# 2. Read vectorised data\n",
    "print(\"Reading vectorized data...\")\n",
    "X_train, y_train = thrember.read_vectorized_features(data_path, subset=\"train\")\n",
    "X_test, y_test = thrember.read_vectorized_features(data_path, subset=\"test\")\n",
    "X_challenge, y_challenge = thrember.read_vectorized_features(data_path, subset=\"challenge\")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Challenge set shape: {X_challenge.shape}\")\n",
    "print(\"Multi-file-type dataset ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a20d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extended Experiment A: Model Comparison on Multi-File-Type Dataset ---\n",
      "\n",
      "--- Processing Model: Logistic Regression ---\n",
      "Completed. ROC AUC: 0.6604, Training Time: 62.33 seconds\n",
      "\n",
      "--- Processing Model: Random Forest ---\n",
      "Completed. ROC AUC: 0.9882, Training Time: 151.05 seconds\n",
      "\n",
      "--- Processing Model: LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 273000, number of negative: 273000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.671125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 188027\n",
      "[LightGBM] [Info] Number of data points in the train set: 546000, number of used features: 1040\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zheng/VisualStudioCodeProjects/EMBER2024/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed. ROC AUC: 0.9923, Training Time: 130.23 seconds\n",
      "\n",
      "--- Processing Model: MLP Classifier ---\n",
      "Completed. ROC AUC: 0.6781, Training Time: 90.76 seconds\n",
      "\n",
      "\n",
      "--- Multi-File-Type Dataset Performance Comparison ---\n",
      "| Model               |   ROC AUC |   Training Time (s) |\n",
      "|:--------------------|----------:|--------------------:|\n",
      "| LightGBM            |  0.992314 |            130.228  |\n",
      "| Random Forest       |  0.988226 |            151.055  |\n",
      "| MLP Classifier      |  0.67812  |             90.7587 |\n",
      "| Logistic Regression |  0.660355 |             62.3295 |\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "\n",
    "print(\"--- Extended Experiment A: Model Comparison on Multi-File-Type Dataset ---\")\n",
    "\n",
    "# 1. Define models for comparison\n",
    "# Store each model and its name in a dictionary for easy iteration\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=100, solver='liblinear'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=500, num_leaves=64, min_child_samples=100, random_state=42),\n",
    "    \"MLP Classifier\": MLPClassifier(random_state=42, max_iter=300)\n",
    "}\n",
    "\n",
    "# 2. Train and evaluate each model\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Processing Model: {model_name} ---\")\n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Prediction\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Evaluation\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"ROC AUC\": roc_auc,\n",
    "        \"Training Time (s)\": training_time\n",
    "    })\n",
    "\n",
    "    print(f\"Completed. ROC AUC: {roc_auc:.4f}, Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# 3. Create a comprehensive results table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\\n--- Multi-File-Type Dataset Performance Comparison ---\")\n",
    "print(results_df.sort_values(by=\"ROC AUC\", ascending=False).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d18cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extended Experiment B: Performance Analysis on Individual File Types ---\n",
      "Reading metadata to identify file types...\n",
      "Metadata loaded:\n",
      "  Training samples: 546000\n",
      "  Test samples: 126000\n",
      "\n",
      "File type distribution in training set:\n",
      "shape: (4, 2)\n",
      "┌───────────┬────────┐\n",
      "│ file_type ┆ count  │\n",
      "│ ---       ┆ ---    │\n",
      "│ str       ┆ u32    │\n",
      "╞═══════════╪════════╡\n",
      "│ ELF       ┆ 26000  │\n",
      "│ APK       ┆ 208000 │\n",
      "│ PDF       ┆ 52000  │\n",
      "│ Dot_Net   ┆ 260000 │\n",
      "└───────────┴────────┘\n",
      "\n",
      "File type distribution in test set:\n",
      "shape: (4, 2)\n",
      "┌───────────┬───────┐\n",
      "│ file_type ┆ count │\n",
      "│ ---       ┆ ---   │\n",
      "│ str       ┆ u32   │\n",
      "╞═══════════╪═══════╡\n",
      "│ Dot_Net   ┆ 60000 │\n",
      "│ APK       ┆ 48000 │\n",
      "│ PDF       ┆ 12000 │\n",
      "│ ELF       ┆ 6000  │\n",
      "└───────────┴───────┘\n",
      "\n",
      "Creating file type labels for vectorized data...\n",
      "Training file types shape: (546000,)\n",
      "Test file types shape: (126000,)\n",
      "Vectorized training data shape: (546000, 2568)\n",
      "Vectorized test data shape: (126000, 2568)\n",
      "Data alignment verified!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Extended Experiment B: Performance Analysis on Individual File Types ---\")\n",
    "\n",
    "# Step 1: Read metadata to get file type information\n",
    "print(\"Reading metadata to identify file types...\")\n",
    "database_path = '/Users/zheng/VisualStudioCodeProjects/EMBER2024/database/'\n",
    "train_df, test_df, challenge_df = thrember.read_metadata(database_path)\n",
    "\n",
    "print(f\"Metadata loaded:\")\n",
    "print(f\"  Training samples: {len(train_df)}\")\n",
    "print(f\"  Test samples: {len(test_df)}\")\n",
    "\n",
    "# Step 2: Check file type distribution\n",
    "print(\"\\nFile type distribution in training set:\")\n",
    "print(train_df['file_type'].value_counts())\n",
    "\n",
    "print(\"\\nFile type distribution in test set:\")\n",
    "print(test_df['file_type'].value_counts())\n",
    "\n",
    "# Step 3: Create file type mapping for vectorized data\n",
    "# We need to match the order of samples in vectorized data with metadata\n",
    "print(\"\\nCreating file type labels for vectorized data...\")\n",
    "\n",
    "# Get file types for training and test sets\n",
    "train_file_types = train_df['file_type'].to_numpy()\n",
    "test_file_types = test_df['file_type'].to_numpy()\n",
    "\n",
    "print(f\"Training file types shape: {train_file_types.shape}\")\n",
    "print(f\"Test file types shape: {test_file_types.shape}\")\n",
    "print(f\"Vectorized training data shape: {X_train.shape}\")\n",
    "print(f\"Vectorized test data shape: {X_test.shape}\")\n",
    "\n",
    "# Verify data alignment\n",
    "if len(train_file_types) == X_train.shape[0] and len(test_file_types) == X_test.shape[0]:\n",
    "    print(\"Data alignment verified!\")\n",
    "else:\n",
    "    print(\"Data alignment issue detected!\")\n",
    "    print(f\"Metadata train samples: {len(train_file_types)}, Vectorized train samples: {X_train.shape[0]}\")\n",
    "    print(f\"Metadata test samples: {len(test_file_types)}, Vectorized test samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78dab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Individual File Type Analysis ---\n",
      "\n",
      "============================================================\n",
      "ANALYZING FILE TYPE: APK\n",
      "============================================================\n",
      "Training samples: 208000\n",
      "Test samples: 48000\n",
      "Positive ratio (train): 0.500\n",
      "Positive ratio (test): 0.500\n",
      "\n",
      "--- Processing Logistic Regression on APK ---\n",
      "ROC AUC: 0.6239, Training Time: 11.36s\n",
      "\n",
      "--- Processing Random Forest on APK ---\n",
      "ROC AUC: 0.9776, Training Time: 52.26s\n",
      "\n",
      "--- Processing LightGBM on APK ---\n",
      "[LightGBM] [Info] Number of positive: 104000, number of negative: 104000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.267727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 171614\n",
      "[LightGBM] [Info] Number of data points in the train set: 208000, number of used features: 686\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zheng/VisualStudioCodeProjects/EMBER2024/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9871, Training Time: 60.23s\n",
      "\n",
      "--- Processing MLP Classifier on APK ---\n",
      "ROC AUC: 0.5598, Training Time: 107.06s\n",
      "\n",
      "============================================================\n",
      "ANALYZING FILE TYPE: Dot_Net\n",
      "============================================================\n",
      "Training samples: 260000\n",
      "Test samples: 60000\n",
      "Positive ratio (train): 0.500\n",
      "Positive ratio (test): 0.500\n",
      "\n",
      "--- Processing Logistic Regression on Dot_Net ---\n",
      "ROC AUC: 0.6842, Training Time: 25.72s\n",
      "\n",
      "--- Processing Random Forest on Dot_Net ---\n",
      "ROC AUC: 0.9951, Training Time: 63.86s\n",
      "\n",
      "--- Processing LightGBM on Dot_Net ---\n",
      "[LightGBM] [Info] Number of positive: 130000, number of negative: 130000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.874984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 191471\n",
      "[LightGBM] [Info] Number of data points in the train set: 260000, number of used features: 1039\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zheng/VisualStudioCodeProjects/EMBER2024/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9981, Training Time: 75.94s\n",
      "\n",
      "--- Processing MLP Classifier on Dot_Net ---\n",
      "ROC AUC: 0.8592, Training Time: 34.30s\n",
      "\n",
      "============================================================\n",
      "ANALYZING FILE TYPE: PDF\n",
      "============================================================\n",
      "Training samples: 52000\n",
      "Test samples: 12000\n",
      "Positive ratio (train): 0.500\n",
      "Positive ratio (test): 0.500\n",
      "\n",
      "--- Processing Logistic Regression on PDF ---\n",
      "ROC AUC: 0.7713, Training Time: 3.45s\n",
      "\n",
      "--- Processing Random Forest on PDF ---\n",
      "ROC AUC: 0.9890, Training Time: 9.65s\n",
      "\n",
      "--- Processing LightGBM on PDF ---\n",
      "[LightGBM] [Info] Number of positive: 26000, number of negative: 26000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 159800\n",
      "[LightGBM] [Info] Number of data points in the train set: 52000, number of used features: 664\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zheng/VisualStudioCodeProjects/EMBER2024/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9912, Training Time: 24.74s\n",
      "\n",
      "--- Processing MLP Classifier on PDF ---\n",
      "ROC AUC: 0.8144, Training Time: 10.43s\n",
      "\n",
      "============================================================\n",
      "ANALYZING FILE TYPE: ELF\n",
      "============================================================\n",
      "Training samples: 26000\n",
      "Test samples: 6000\n",
      "Positive ratio (train): 0.500\n",
      "Positive ratio (test): 0.500\n",
      "\n",
      "--- Processing Logistic Regression on ELF ---\n",
      "ROC AUC: 0.6635, Training Time: 1.09s\n",
      "\n",
      "--- Processing Random Forest on ELF ---\n",
      "ROC AUC: 0.9903, Training Time: 3.91s\n",
      "\n",
      "--- Processing LightGBM on ELF ---\n",
      "[LightGBM] [Info] Number of positive: 13000, number of negative: 13000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166948\n",
      "[LightGBM] [Info] Number of data points in the train set: 26000, number of used features: 683\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zheng/VisualStudioCodeProjects/EMBER2024/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9931, Training Time: 18.44s\n",
      "\n",
      "--- Processing MLP Classifier on ELF ---\n",
      "ROC AUC: 0.8692, Training Time: 16.92s\n",
      "\n",
      "============================================================\n",
      "ALL FILE TYPE ANALYSIS COMPLETED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    " # Step 4: Perform model comparison on each file type\n",
    "print(\"--- Starting Individual File Type Analysis ---\")\n",
    "\n",
    "# Define file types to analyze\n",
    "file_types_to_analyze = ['APK', 'Dot_Net', 'PDF', 'ELF']\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000, solver='liblinear'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=500, num_leaves=64, min_child_samples=100, random_state=42),\n",
    "    \"MLP Classifier\": MLPClassifier(random_state=42, max_iter=300)\n",
    "}\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "# Outer loop: iterate through file types\n",
    "for file_type in file_types_to_analyze:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ANALYZING FILE TYPE: {file_type}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Create masks for current file type\n",
    "    train_mask = train_file_types == file_type\n",
    "    test_mask = test_file_types == file_type\n",
    "\n",
    "    # Extract data for current file type\n",
    "    X_train_subset = X_train[train_mask]\n",
    "    y_train_subset = y_train[train_mask]\n",
    "    X_test_subset = X_test[test_mask]\n",
    "    y_test_subset = y_test[test_mask]\n",
    "\n",
    "    print(f\"Training samples: {X_train_subset.shape[0]}\")\n",
    "    print(f\"Test samples: {X_test_subset.shape[0]}\")\n",
    "    print(f\"Positive ratio (train): {y_train_subset.mean():.3f}\")\n",
    "    print(f\"Positive ratio (test): {y_test_subset.mean():.3f}\")\n",
    "\n",
    "    # Inner loop: iterate through models\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n--- Processing {model_name} on {file_type} ---\")\n",
    "        # Training\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_subset, y_train_subset)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Prediction\n",
    "        y_pred_proba = model.predict_proba(X_test_subset)[:, 1]\n",
    "\n",
    "        # Evaluation\n",
    "        roc_auc = roc_auc_score(y_test_subset, y_pred_proba)\n",
    "\n",
    "        # Store results\n",
    "        all_results.append({\n",
    "            \"File_Type\": file_type,\n",
    "            \"Model\": model_name,\n",
    "            \"ROC_AUC\": roc_auc,\n",
    "            \"Training_Time\": training_time,\n",
    "            \"Train_Samples\": X_train_subset.shape[0],\n",
    "            \"Test_Samples\": X_test_subset.shape[0]\n",
    "        })\n",
    "\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}, Training Time: {training_time:.2f}s\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALL FILE TYPE ANALYSIS COMPLETED!\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
